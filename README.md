# Document Question-Answering with Local RAG in Android

> A simple Android app that allows the user to add a PDF/DOCX document and ask natural-language questions whose 
> answers are generated by the means of an LLM


## Goals

- Demonstrate the collective use of an on-device vector database, embeddings model and a custom text-splitter to build a retrieval-augmented generation (RAG) based pipeline for simple document question-answering
- Use modern Android development practices and recommended architecture guidelines
- Explore and suggest better tools/alternatives for building fully offline, on-device RAG pipeline for Android with minimum compute and storage requirements

| Feature            | On-Device | Remote |
|--------------------|----------|--------|
| Sentence Embedding | ✅        |        |
| Text Splitter      | ✅        |        |
| Vector Database    | ✅        |        |
| LLM                | ✅        | ✅      |

## Setup

1. Clone the `main` branch, 

```bash
$> git clone --depth=1 https://github.com/aruneoz/ondevicerag
```

2. [Get an API key from Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key) to use the Gemini API. Copy 
the key and paste it in `local.properties` present in the root directory of the project,

```
geminiKey="AIza[API_KEY_HERE]"
```

Perform a Gradle sync, and run the application. 

## Tools

1. [Apache POI](https://poi.apache.org/) and [iTextPDF](https://github.com/itext/itextpdf) for parsing DOCX and PDF documents
2. [ObjectBox](https://objectbox.io/) for on-device vector-store and NoSQL database
3. [Sentence Embeddings (`all-MiniLM-L6-V2`)](https://github.com/shubham0204/Sentence-Embeddings-Android) for generating on-device text/sentence embeddings
4. [Gemini Android SDK](https://developer.android.com/ai/google-ai-client-sdk) as a hosted large-language model (Uses Gemini-1.5-Flash)

## Working 

The basic working flow on the app is as follows:

1. When the user selects a PDF/DOCX document (the only ones which can be imported for now), the text is parsed with 
the libraries mentioned in (1) of [Tools](#tools). See [PDFReader.kt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/java/com/ml/shubham0204/docqa/domain/readers/PDFReader.kt) and [DOCXReader.kt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/java/com/ml/shubham0204/docqa/domain/readers/DOCXReader.kt) for reference.
2. Chunks or overlapping sub-sequences are produced from the text, given the size of sequence (`chunkSize`) and 
the extent of overlap between two sequences (`chunkOverlap`). See [WhiteSpaceSplitter.kt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/java/com/ml/shubham0204/docqa/domain/splitters/WhiteSpaceSplitter.kt) for reference.
3. Each chunk is encoded into a fixed-size vector i.e. a text embedding. The embeddings are inserted in the vector database, with each chunk/embedding having a distinct `chunkId`. See [SentenceEmbeddingProvider.kt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/java/com/ml/shubham0204/docqa/domain/embeddings/SentenceEmbeddingProvider.kt) for reference.
4. When the user submits a query, we find the top-K most similar chunks from the database by comparing their embeddings.
5. The chunks corresponding to the nearest embeddings are injected into a pre-built prompt along with the query, which is provided to the LLM. The LLM generates a well-formed natural language answer to the user's query. See [GeminiRemoteAPI.kt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/java/com/ml/shubham0204/docqa/domain/llm/GeminiRemoteAPI.kt) for reference.

See the [prompt](https://github.com/shubham0204/Android-Document-QA/blob/main/app/src/main/res/values/strings.xml),

```text
You are an intelligent search engine. You will be provided with retrieved context, as well as the users query. 
Your job is to understand the user query, and answer based on the retrieved context below. 
Think step by step and answer must be relevant and based on the only the retrieved context. 
Ensure your answer is logical and uses professional language.

Here is the retrieved context
--------------------------------------------------
$CONTEXT
--------------------------------------------------
Here is the user\'s query: $QUERY
```


